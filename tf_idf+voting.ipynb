{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_idf+voting.ipynb",
      "provenance": [],
      "mount_file_id": "1ueRuMj8D57KDWKqZwx4L25M35MQ4VVA-",
      "authorship_tag": "ABX9TyMUAsgBgn/b5ylbL1Eigabf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahraDehghanian97/classify_text/blob/master/tf_idf%2Bvoting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWheA6CSj3ft"
      },
      "source": [
        "# **Mount google drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r3444wwj6Mr",
        "outputId": "0d75d810-8231-43f2-ef82-94b79b58412e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTSvl-QYjyo3"
      },
      "source": [
        "# **prerequisit**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2F_EIyczeua"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import groupby\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils.extmath import density"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tmrWx7z1Uce"
      },
      "source": [
        "# **load dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJf9TL43Sk7k"
      },
      "source": [
        "train_path = '/content/drive/MyDrive/Colab Notebooks/labeling_application/train_set.csv'\n",
        "test_path = '/content/drive/MyDrive/Colab Notebooks/labeling_application/test_set.csv'\n",
        "result_path = '/content/drive/MyDrive/Colab Notebooks/labeling_application/prediction_all.csv'\n",
        "model_path = '/content/drive/MyDrive/Colab Notebooks/labeling_application/tfidf.model'\n",
        "stop_path = '/content/drive/MyDrive/Colab Notebooks/labeling_application/stop_word.csv'"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRE6T9PCTueG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ff38c0b-bbdb-4881-8a27-764010fab684"
      },
      "source": [
        "# this function extract important word of each game\n",
        "def prepare_string(string):\n",
        "    result = \"\"\n",
        "    # remove html tags from string\n",
        "    TAG_RE = re.compile(r'<[^>]+>')\n",
        "    string = TAG_RE.sub('', string)\n",
        "    # remove punctuation mark\n",
        "    string = re.sub(\"[!()@.?؛:،-]\",'', string)\n",
        "    strings=string.split()\n",
        "    # remove stop word\n",
        "    for s in strings : \n",
        "      s = s.strip()\n",
        "      if not s in stop_word.values and s!='' : \n",
        "        result = result + \" \"+s\n",
        "    return result\n",
        "\n",
        "# load short list of stop word \n",
        "stop_word = pd.read_csv(stop_path ,header = None, encoding = 'utf8')\n",
        "\n",
        "# load train set\n",
        "docs = []\n",
        "id_docs = []\n",
        "sentences = []\n",
        "word_count = []\n",
        "labels = []\n",
        "train_data = pd.read_csv(train_path, encoding='utf8')\n",
        "for d in train_data.values:\n",
        "    id_docs.append(d[0])\n",
        "    p_string = prepare_string(d[1])\n",
        "    docs.append(p_string)\n",
        "    sentences.extend(p_string)\n",
        "    word_count.append(len(p_string))\n",
        "    labels.append(d[2])\n",
        "# distinct_words = list(set(sentences))\n",
        "\n",
        "# split validation data\n",
        "id_docs_validation = id_docs[-150:]\n",
        "id_docs = id_docs[:-150]\n",
        "docs_validation = docs[-150:]\n",
        "docs = docs [:-150]\n",
        "word_count_validation = word_count[-150:]\n",
        "word_count = word_count[:-150]\n",
        "labels_validation = labels[-150:]\n",
        "labels = labels[:-150]\n",
        "\n",
        "\n",
        "# load test set\n",
        "docs_test = []\n",
        "id_docs_test = []\n",
        "test_data = pd.read_csv(test_path, encoding='utf8')\n",
        "for d in test_data.values:\n",
        "    id_docs_test.append(d[0])\n",
        "    docs_test.append(prepare_string(d[1]))\n",
        "\n",
        "print(docs[0])\n",
        "print(id_docs_test[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " بازی مین برنامه فکری باید مین موجود صفحه بازی کشف قابلیت برنامه عبارتند دارای سطوح دشواری آسان سخت امکان تعریف بازی سفارشی نمایش آمار بازی عملکرد ذخیره بازی ناتمام میتوانید آینده قسمت بازی ذخیره مراجعه بازی ادامه دهید سایر برنامه بازی متنوع نیز دیدن سپاسگزارم\n",
            "40000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH6_KDhEOepb"
      },
      "source": [
        "# **tf-idf**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOPu5FV5KUUo"
      },
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(docs)\n",
        "X_validation = vectorizer.transform(docs_validation)\n",
        "X_test_f = vectorizer.transform(docs_test)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4AwS47Y7o_C"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfbM7Aor8CXb",
        "outputId": "d58be540-9741-4179-dba3-4f0bbfed00a5"
      },
      "source": [
        "def benchmark(model):\n",
        "  model.fit(X_train, labels)\n",
        "  prediction = model.predict(X_test)\n",
        "  return prediction\n",
        "\n",
        "validation = False\n",
        "X_test = X_test_f\n",
        "if validation :\n",
        "  X_test = X_validation\n",
        "\n",
        "results = []\n",
        "for clf, name in (\n",
        "        (RidgeClassifier(tol=1e-2, solver=\"sag\"), \"Ridge Classifier\"),\n",
        "        (Perceptron(max_iter=50), \"Perceptron\"),\n",
        "        (PassiveAggressiveClassifier(max_iter=50) ,\"Passive-Aggressive\"),\n",
        "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
        "        (RandomForestClassifier(), \"Random forest\")):\n",
        "    results.append(benchmark(clf))\n",
        "\n",
        "for penalty in [\"l2\", \"l1\"]:\n",
        "    results.append(benchmark(LinearSVC(penalty=penalty, dual=False, tol=1e-3)))     # Train Liblinear model\n",
        "    results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50,penalty=penalty))) # Train SGD model\n",
        "results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50,penalty=\"elasticnet\")))# Train SGD with Elastic Net penalty\n",
        "results.append(benchmark(NearestCentroid())) # Train NearestCentroid without threshold\n",
        "results.append(benchmark(MultinomialNB(alpha=.01))) # TrainMultinomial Naive Bayes classifier\n",
        "results.append(benchmark(BernoulliNB(alpha=.01))) # Train Bernoulli Naive Bayes classifier \n",
        "results.append(benchmark(ComplementNB(alpha=.1))) # Train complement Naive Bayes classifier\n",
        "results.append(benchmark(Pipeline([('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", \n",
        "                          dual=False,tol=1e-3))),('classification', LinearSVC(penalty=\"l2\"))]))) # LinearSVC with L1-based feature selection\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:558: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n",
            "  '\"sag\" solver requires many iterations to fit '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZfXlA5EDyMS"
      },
      "source": [
        "find most probable class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBZofRz2_we4"
      },
      "source": [
        "new_results = []\n",
        "for i in range(len(results[0])):\n",
        "  temp = []\n",
        "  for j in range(len(results)):\n",
        "    temp.append(results[j][i])\n",
        "  new_results.append(temp)\n",
        "labels_prediction = []\n",
        "for result in new_results :\n",
        "    group = groupby(result)\n",
        "    final_tag =  max(group, key=lambda k: len(list(k[1])))\n",
        "    labels_prediction.append(final_tag[0])\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4f30iMbEBTH"
      },
      "source": [
        "show accuracy or save labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGV2hJwDDM31",
        "outputId": "4059d8a6-df04-4f6c-8045-bac058b9edbe"
      },
      "source": [
        "if validation :\n",
        "  score =balanced_accuracy_score(labels_validation,labels_prediction)\n",
        "  print(score)\n",
        "else:\n",
        "  data =  { 'id' : id_docs_test ,'label' : labels_prediction }\n",
        "  df = pd.DataFrame(data)\n",
        "  df.to_csv(result_path, index=False)\n",
        "  print(\"done\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}